{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO9wRmgG3iWr/Lsy4E1OJcn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KadinRelefourd/CNNandResnetClassifier/blob/main/CNNclassify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing THOP for  parameter counting"
      ],
      "metadata": {
        "id": "uFcdHnDwj2A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeKQe4c3jtil",
        "outputId": "ace169aa-a0a5-4573-ded9-a4e025c83cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.11/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2  # OpenCV for image processing\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from thop import profile  # For counting MACs and parameters\n",
        "from resnet20_cifar import resnet20  # Import the pretrained ResNet-20 model\n",
        "import time\n"
      ],
      "metadata": {
        "id": "qEdcwFn4gdWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU Availability"
      ],
      "metadata": {
        "id": "dVEnHd0io8Pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#ranodom_seeds = [53,152,512]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO79mektpAyx",
        "outputId": "913968dc-25ca-46f7-b6dd-648c96daec82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet Loaded"
      ],
      "metadata": {
        "id": "8N0sJeUdiOZR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAxxOO8re5YM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4d3cf6-64fb-43b7-f886-f276edaa0186"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# This resnet20 model is trained with Normalization augmentation for training data:\n",
        "# transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "# the above transforms.Normalize(xxxx) is in the  testing data loader.\n",
        "model = resnet20()\n",
        "model_path = \"./resnet20_cifar10_pretrained.pt\"\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Training and Testing data"
      ],
      "metadata": {
        "id": "boT08R7XkDgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(\n",
        "    root='./data.cifar10',\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root='./data.cifar10',\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "NND2bHB1kHXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model"
      ],
      "metadata": {
        "id": "eEL-_-dDkObS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        # initialize parent class\n",
        "        super(Net, self).__init__()  # Initialize the parent class (nn.Module)\n",
        "\n",
        "        # create sequential model architecture\n",
        "        self.model = nn.Sequential(\n",
        "            # first conv layer with 32 filters\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=0),  # Conv layer: 3 input channels (RGB), 32 output channels, 5x5 kernel\n",
        "            # apply relu activation\n",
        "            nn.ReLU(),  # Apply ReLU activation function\n",
        "            # reduce spatial dimensions\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Max pooling with 2x2 window, stride 2 (reduces spatial size by half)\n",
        "\n",
        "            # second conv layer with 64 filters\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),  # Conv layer: 32 -> 64 channels, 3x3 kernel\n",
        "            # apply relu activation\n",
        "            nn.ReLU(),  # Apply ReLU activation\n",
        "            # reduce spatial dimensions again\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Max pooling, reduces spatial dimensions\n",
        "\n",
        "            # third conv layer maintaining 64 filters\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),  # Another convolution layer, same 64 channels\n",
        "            # apply relu activation\n",
        "            nn.ReLU(),  # Apply ReLU activation\n",
        "\n",
        "            # convert 2d feature maps to 1d vector\n",
        "            nn.Flatten(),  # Flatten feature maps into a 1D tensor before passing into fully connected layers\n",
        "\n",
        "            # first fully connected layer\n",
        "            nn.Linear(64 * 7 * 7, 512),  # Fully connected layer: input size based on feature map size, output 512 neurons\n",
        "            # normalize activations\n",
        "            nn.BatchNorm1d(512),  # Apply batch normalization for stable training\n",
        "            # prevent overfitting\n",
        "            nn.Dropout(0.5),  # Dropout (50%) to reduce overfitting\n",
        "            # apply relu activation\n",
        "            nn.ReLU(),  # Apply ReLU activation\n",
        "\n",
        "            # second fully connected layer\n",
        "            nn.Linear(512, 256),  # Fully connected layer: 512 -> 256 neurons\n",
        "            # normalize activations\n",
        "            nn.BatchNorm1d(256),  # Apply batch normalization\n",
        "            # prevent overfitting\n",
        "            nn.Dropout(0.5),  # Dropout (50%)\n",
        "            # apply relu activation\n",
        "            nn.ReLU(),  # Apply ReLU activation\n",
        "\n",
        "            # output layer for 10 classes\n",
        "            nn.Linear(256, 10)  # Output layer: 10 neurons for classification (e.g., 10 classes in CIFAR-10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # pass input through model layers\n",
        "        return self.model(x)  # Forward pass: pass input through the model\n",
        "\n",
        "\n",
        "\n",
        "# create model instance and move to device\n",
        "model = Net().to(device)"
      ],
      "metadata": {
        "id": "DNCIdNd3kLcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "0dCEGYF5PV7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define cross entropy loss for classification\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# setup adam optimizer for training\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "roLcdL5cPYLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving Model"
      ],
      "metadata": {
        "id": "pVvBg5LKASK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save():\n",
        "    # Save model in the model folder\n",
        "    if not os.path.exists('./model'):\n",
        "        os.makedirs('./model')\n",
        "    torch.save(model.state_dict(), './model/model.ckpt')\n",
        "    print(f\"Model saved in file: ./model/model.ckpt\")"
      ],
      "metadata": {
        "id": "ZqPhbfEcAVtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ],
      "metadata": {
        "id": "S7MqZ3QZAfto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load(model_path):\n",
        "    # Load model for classification\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "hEHIeFRZAdi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define cross entropy loss for classification\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# setup adam optimizer for training\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "PbMGi4F7kaP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Accuracy"
      ],
      "metadata": {
        "id": "S8h3CoOUkcjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_accuracy():\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # disable gradient calculation\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in train_loader:\n",
        "            # get model predictions\n",
        "            outputs = model(inputs)\n",
        "            # get predicted class\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            # count total samples\n",
        "            total += targets.size(0)\n",
        "            # count correct predictions\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    # calculate accuracy percentage\n",
        "    return 100 * correct / total"
      ],
      "metadata": {
        "id": "L_UHRGZCkelW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mean asnd stadard deviation"
      ],
      "metadata": {
        "id": "YbXV8wP_PSOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"calculate training statistics\"\"\"\n",
        "def calculate_test_stats(test_accuracies):\n",
        "    # convert list to numpy array\n",
        "    test_accuracies = np.array(test_accuracies)\n",
        "\n",
        "    # calculate mean accuracy\n",
        "    mean_accuracy = np.mean(test_accuracies)\n",
        "\n",
        "    # calculate standard deviation\n",
        "    std_accuracy = np.std(test_accuracies)\n",
        "\n",
        "    # print\n",
        "    print(f\"Mean accuracy: {mean_accuracy:.2f}%\")\n",
        "    print(f\"Standard deviation: {std_accuracy:.2f}%\")\n",
        "\n",
        "    return mean_accuracy, std_accuracy"
      ],
      "metadata": {
        "id": "0BKDx7AOPYmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "B16G40jwL1gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    total_loss = 0.0\n",
        "    # disable gradient calculation for inference\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            # move data to device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # get model predictions\n",
        "            outputs = model(inputs)\n",
        "            # calculate loss\n",
        "            loss = loss_func(outputs, labels)\n",
        "            # accumulate loss\n",
        "            total_loss += loss.item()\n",
        "            # get predicted class\n",
        "            _, predicted = outputs.max(1)\n",
        "            # count total samples\n",
        "            total_test += labels.size(0)\n",
        "            # count correct predictions\n",
        "            correct_test += predicted.eq(labels).sum().item()\n",
        "    # calculate accuracy percentage\n",
        "    accuracy = correct_test / total_test * 100\n",
        "    # calculate average loss\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    return accuracy, avg_loss\n"
      ],
      "metadata": {
        "id": "g3Nha5x-L3ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visuaiilization"
      ],
      "metadata": {
        "id": "9cxBqjfiBPJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_conv_layer(image_path):\n",
        "    # load trained model\n",
        "    model = load('./model/model.ckpt')\n",
        "    model.eval()\n",
        "\n",
        "    # read input image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(\"Error: Image not found or invalid path.\")\n",
        "        return\n",
        "\n",
        "    # convert color space\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # resize image to network input size\n",
        "    resized = cv2.resize(img, (32, 32))\n",
        "    # prepare tensor and move to device\n",
        "    tensor = transform(resized).unsqueeze(0).to(device)\n",
        "\n",
        "    # setup activation storage\n",
        "    activation = {}\n",
        "    def get_activation(name):\n",
        "        def hook(model, input, output):\n",
        "            # store layer output\n",
        "            activation[name] = output.detach()\n",
        "        return hook\n",
        "\n",
        "    # attach hook to first conv layer\n",
        "    handle = model.model[0].register_forward_hook(get_activation('conv1'))\n",
        "    # perform forward pass\n",
        "    with torch.no_grad():\n",
        "        output = model(tensor)\n",
        "\n",
        "    # get activation maps\n",
        "    feature_maps = activation['conv1'].squeeze(0).cpu()\n",
        "\n",
        "    # create visualization figure\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(32):  # 32 filters in the first conv layer\n",
        "        # create subplot for each filter\n",
        "        plt.subplot(6, 6, i+1)\n",
        "        # display feature map\n",
        "        plt.imshow(feature_maps[i], cmap='viridis')\n",
        "        # hide axes\n",
        "        plt.axis('off')\n",
        "\n",
        "    # adjust layout and save\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('CONV_rslt.png')\n",
        "    plt.close()\n",
        "\n",
        "    # cleanup hook\n",
        "    handle.remove()"
      ],
      "metadata": {
        "id": "mxhXEw2VBVrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Function"
      ],
      "metadata": {
        "id": "k19x2IC9k9Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(seed=None):\n",
        "    if seed is not None:\n",
        "        print(f\"Using random seed: {seed}\")\n",
        "        # set random seeds for reproducibility\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        if torch.cuda.is_available():\n",
        "            # set cuda seeds too\n",
        "            torch.cuda.manual_seed(seed)\n",
        "            torch.backends.cudnn.deterministic = True\n",
        "            torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # print header for training progress\n",
        "    print(f\"{'Epoch':<8}{'Train Loss':<15}{'Train Acc %':<15}{'Test Loss':<15}{'Test Acc %':<15}\")\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(7):  # Train for 10 epochs\n",
        "        # set model to training mode\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            # move data to device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # reset gradients\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass\n",
        "            outputs = model(inputs)\n",
        "            # calculate loss\n",
        "            loss = loss_func(outputs, labels)\n",
        "            # backward pass\n",
        "            loss.backward()\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # accumulate loss\n",
        "            running_loss += loss.item()\n",
        "            # get predicted class\n",
        "            _, predicted = outputs.max(1)\n",
        "            # count total samples\n",
        "            total_train += labels.size(0)\n",
        "            # count correct predictions\n",
        "            correct_train += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # calculate training accuracy\n",
        "        train_accuracy = correct_train / total_train * 100\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # evaluate on test set\n",
        "        test_accuracy, test_loss = test()\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        # print epoch results\n",
        "        print(f\"{epoch + 1:<8}{running_loss / len(train_loader):<15.4f}{train_accuracy:<15.2f}{test_loss:<15.4f}{test_accuracy:<15.2f}\")\n",
        "\n",
        "    # save trained model\n",
        "    save()\n",
        "\n",
        "    # create accuracy plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, 8), train_accuracies, label='Training Accuracy', marker='o', color='blue')\n",
        "    plt.plot(range(1, 8), test_accuracies, label='Testing Accuracy', marker='s', color='red')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Training and Testing Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # save plot to file\n",
        "    plot_path = \"accuracy_plot.png\"  # Save the plot in the current working directory\n",
        "    plt.savefig(plot_path)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Accuracy plot saved to: {plot_path}\")\n",
        "\n",
        "    #calculat and displau mean and stadard eviatoin\n",
        "    mean_acc, std_acc = calculate_test_stats(test_accuracies)\n",
        "\n",
        "\n",
        "    return test_accuracies\n"
      ],
      "metadata": {
        "id": "heCDS93xlAMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Function"
      ],
      "metadata": {
        "id": "0Bl6kh9hlCaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(image_path):\n",
        "    # load trained model\n",
        "    model = load('./model/model.ckpt')\n",
        "    model.eval()\n",
        "\n",
        "    # read input image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(\"Error: Image not found or invalid path.\")\n",
        "        return\n",
        "\n",
        "    # convert color space\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # resize to network input size\n",
        "    resized = cv2.resize(img, (32, 32))\n",
        "    # prepare tensor and move to device\n",
        "    tensor = transform(resized).unsqueeze(0).to(device)\n",
        "\n",
        "    # perform inference\n",
        "    with torch.no_grad():\n",
        "        output = model(tensor)\n",
        "        # get predicted class\n",
        "        _, predicted_class = torch.max(output.data, 1)\n",
        "\n",
        "    # get class names\n",
        "    classes = train_data.classes\n",
        "    print(f'Prediction result: {classes[predicted_class.item()]}')\n",
        "\n",
        "    # visualize activations\n",
        "    ##visualize_conv_layer(image_path)\n"
      ],
      "metadata": {
        "id": "zQbP9DHDlDi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNeet eval funct"
      ],
      "metadata": {
        "id": "kBhi_OyqCnua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet20_eval():\n",
        "    # load resnet model\n",
        "    resnet_model = resnet20().to(device)\n",
        "    resnet_model.load_state_dict(torch.load('./resnet20_cifar10_pretrained.pt'))\n",
        "\n",
        "    # set to evaluation mode\n",
        "    resnet_model.eval()\n",
        "\n",
        "    correct_resnet_test = 0\n",
        "    total_resnet_test = 0\n",
        "\n",
        "    # evaluate without gradients\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            # move data to device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # get model predictions\n",
        "            outputs_resnet = resnet_model(inputs)\n",
        "            # get predicted class\n",
        "            _, predicted_resnet_class = outputs_resnet.max(1)\n",
        "\n",
        "            # count total samples\n",
        "            total_resnet_test += labels.size(0)\n",
        "            # count correct predictions\n",
        "            correct_resnet_test += predicted_resnet_class.eq(labels).sum().item()\n",
        "\n",
        "    # calculate accuracy percentage\n",
        "    accuracy_resnet20 = correct_resnet_test / total_resnet_test * 100\n",
        "    print(f\"ResNet-20 Test Accuracy: {accuracy_resnet20:.2f}%\")"
      ],
      "metadata": {
        "id": "bKMVbS1nCp_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train multiple seeds"
      ],
      "metadata": {
        "id": "JKnRAccmVaIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_multiple_seeds():\n",
        "    seeds = [152, 53, 512]  # List of random seeds to use\n",
        "    accuracies = []  # List to store test accuracies for each seed\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\nTraining with seed: {seed}\")\n",
        "\n",
        "        # Reinitialize the model and optimizer for each seed\n",
        "        model = Net().to(device)  # Reinitialize the model\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)  # Reinitialize the optimizer\n",
        "\n",
        "        # Train the model with the current seed\n",
        "        test_accuracies = train(seed=seed)  # Train with each seed\n",
        "        final_test_accuracy = test_accuracies[-1]  # Get the final test accuracy\n",
        "        accuracies.append(final_test_accuracy)  # Store the final accuracy\n",
        "\n",
        "    # Calculate mean and standard deviation of the accuracies\n",
        "    mean_accuracy = np.mean(accuracies)\n",
        "    std_accuracy = np.std(accuracies)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"\\nTraining with multiple seeds completed.\")\n",
        "    print(f\"Seeds used: {seeds}\")\n",
        "    print(f\"Final test accuracies: {accuracies}\")\n",
        "    print(f\"Mean accuracy: {mean_accuracy:.2f}%\")\n",
        "    print(f\"Standard deviation: {std_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "6gHMziMEVb5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "count macs and params"
      ],
      "metadata": {
        "id": "ytvdX8YR71QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_macs_and_params(model, input_shape=(1, 3, 32, 32)):\n",
        "    dummy_input = torch.randn(input_shape).to(device)\n",
        "    macs, params = profile(model, inputs=(dummy_input,))\n",
        "    print(f\"Model: {model.__class__.__name__}\")\n",
        "    print(f\"MACs: {macs}\")\n",
        "    print(f\"Parameters: {params}\")"
      ],
      "metadata": {
        "id": "aC-c6L588Ajg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inference speed test"
      ],
      "metadata": {
        "id": "cL7VnTtL7UsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_speed_test(model, iterations=100, warmup=10):\n",
        "    # create dummy input\n",
        "    dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "\n",
        "    # set evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # perform warmup iterations\n",
        "    with torch.no_grad():\n",
        "        for _ in range(warmup):\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "    # measure inference time\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(iterations):\n",
        "            # run inference\n",
        "            _ = model(dummy_input)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # calculate average time\n",
        "    avg_time = (end_time - start_time) / iterations\n",
        "    print(f\"Average inference time: {avg_time:.6f} seconds\")"
      ],
      "metadata": {
        "id": "V-VTiqdT7t0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Command Line Prompts"
      ],
      "metadata": {
        "id": "Dh3kfPmslGfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) < 2:\n",
        "        # show usage instructions\n",
        "        print(\"Usage:\")\n",
        "        print(\" python CNNclassify.py train - to train CNN model\")\n",
        "        print(\" python CNNclassify.py test <image_path> - classifies an image\")\n",
        "        print(\" python CNNclassify.py resnet20 - evaluates ResNet-20 on CIFAR-10\")\n",
        "        print(\" python CNNclassify.py train_multiple_seeds - tries to wiht multiple train with multiple seeds but doesn twokr\")\n",
        "        print(\" python CNNclassify.py count_macs - count MACs and parameters of each model\")\n",
        "        print(\" python CNNclassify.py inference_speed - tests inference speed of each model\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # get command from arguments\n",
        "    command = sys.argv[1]\n",
        "\n",
        "    if command == \"train\":\n",
        "        # train with specified seed\n",
        "        train(seed=none)\n",
        "        image_path = \"./cat1.png\"\n",
        "        # visualize layer activations\n",
        "        visualize_conv_layer(image_path)\n",
        "    elif command == \"test\" and len(sys.argv) > 2:\n",
        "        # classify provided image\n",
        "        classify(sys.argv[2])\n",
        "    elif command == \"resnet20\":\n",
        "        # evaluate resnet performance\n",
        "        resnet20_eval()\n",
        "    elif command == \"train_multiple_seeds\":\n",
        "        # train with different seeds\n",
        "        train_multiple_seeds()\n",
        "    elif command == \"count_macs\":\n",
        "        # count operations in custom model\n",
        "        count_macs_and_params(model)\n",
        "        # load resnet model\n",
        "        resnet_model = resnet20().to(device)\n",
        "        resnet_model.load_state_dict(torch.load('./resnet20_cifar10_pretrained.pt'))\n",
        "        # count operations in resnet\n",
        "        count_macs_and_params(resnet_model)\n",
        "    elif command == \"inference_speed\":\n",
        "        # test custom model speed\n",
        "        print(\"My Model\")\n",
        "        inference_speed_test(model)\n",
        "        # load resnet model\n",
        "        resnet_model = resnet20().to(device)\n",
        "        resnet_model.load_state_dict(torch.load('./resnet20_cifar10_pretrained.pt'))\n",
        "        # test resnet speed\n",
        "        print(\"ResNet-20\")\n",
        "        inference_speed_test(resnet_model)\n",
        "    else:\n",
        "        print(\"Invalid command or missing parameters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgxauNA6lK_I",
        "outputId": "a64079b5-e3ef-4f59-b62c-43fa2372a5b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid command or missing parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python CNNclassify.py test cat1.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFT13uMyDU7m",
        "outputId": "0fefb018-d45b-45c1-e55e-fe80d47c5027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Prediction result: frog\n"
          ]
        }
      ]
    }
  ]
}